{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5fa91b9-fab3-4680-8e1a-e0f2670718a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.7.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "WARNING:tensorflow:From /var/folders/gh/ssm1fz4j12j05_fcyw53gxs00000gn/T/ipykernel_13580/1085823539.py:21: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 15:07:06.101249: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-11 15:07:06.101386: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "from urllib import request\n",
    "\n",
    "from dontpatronizeme.semeval_2022 import dont_patronize_me as dpm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, SpatialDropout1D, Bidirectional, Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3cf74d8-70cb-4efd-aff8-c12cda8fd009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfda3d13-b674-4882-aaa1-b5086753c018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10469, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country_code</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@@24942188</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>ph</td>\n",
       "      <td>We 're living in times of absolute insanity , ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@@21968160</td>\n",
       "      <td>migrant</td>\n",
       "      <td>gh</td>\n",
       "      <td>In Libya today , there are countless number of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@@16584954</td>\n",
       "      <td>immigrant</td>\n",
       "      <td>ie</td>\n",
       "      <td>White House press secretary Sean Spicer said t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@@7811231</td>\n",
       "      <td>disabled</td>\n",
       "      <td>nz</td>\n",
       "      <td>Council customers only signs would be displaye...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@@1494111</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ca</td>\n",
       "      <td>\" Just like we received migrants fleeing El Sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       art_id    keyword country_code  \\\n",
       "0                                       \n",
       "1  @@24942188   hopeless           ph   \n",
       "2  @@21968160    migrant           gh   \n",
       "3  @@16584954  immigrant           ie   \n",
       "4   @@7811231   disabled           nz   \n",
       "5   @@1494111    refugee           ca   \n",
       "\n",
       "                                                text  label  \n",
       "0                                                            \n",
       "1  We 're living in times of absolute insanity , ...      0  \n",
       "2  In Libya today , there are countless number of...      0  \n",
       "3  White House press secretary Sean Spicer said t...      0  \n",
       "4  Council customers only signs would be displaye...      0  \n",
       "5  \" Just like we received migrants fleeing El Sa...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - <par_id> is a unique id for each one of the paragraphs in the corpus.\n",
    "# - <art_id> is the document id in the original NOW corpus (News on Web: https://www.english-corpora.org/now/).\n",
    "# - <keyword> is the search term used to retrieve texts about a target community.\n",
    "# - <country_code> is a two-letter ISO Alpha-2 country code for the source media outlet.\n",
    "# - <text> is the paragraph containing the keyword.\n",
    "# - <label> is an integer between 0 and 4. Each paragraph has been annotated by two annotators as 0 (No PCL), 1 (borderline PCL) and 2 (contains PCL). The combined annotations have been used in the following graded scale:\n",
    "\n",
    "data = pd.read_csv('dontpatronizeme_pcl.tsv', skiprows=4, sep='\\t', header=None, index_col=0)\n",
    "data.columns = ['art_id', 'keyword', 'country_code', 'text', 'label']\n",
    "print(data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57691086-18f4-4da7-92de-55ab0ac26a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4341  4136 10352 ...  8382  8383  8384]\n",
      "[ 4046  1279  8330 ... 10464 10465 10466]\n"
     ]
    }
   ],
   "source": [
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data)*test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return train_indices, test_indices, data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "def split_train_test2(data):\n",
    "    train = pd.read_csv('train_semeval_parids-labels.csv', index_col=0)\n",
    "    test =  pd.read_csv('dev_semeval_parids-labels.csv', index_col=0)\n",
    "    train_idx = train.index.values\n",
    "    print(train_idx)\n",
    "    test_idx = test.index.values\n",
    "    print(test_idx)\n",
    "    return train_idx, test_idx, data.iloc[train_idx-1], data.iloc[test_idx-1]\n",
    "\n",
    "\n",
    "# which indices to use?\n",
    "semeval_idx = True\n",
    "\n",
    "np.random.seed(42)\n",
    "if semeval_idx:\n",
    "    # using semeval's train/devs set:\n",
    "    train_indices, test_indices, train_set, test_set = split_train_test2(data)\n",
    "else:\n",
    "    # using custom randomizer\n",
    "    train_indices, test_indices, train_set, test_set = split_train_test(data, 0.2)\n",
    "\n",
    "# print(train_set.text.head(5), train_set.shape)\n",
    "# print(test_set.head(5), test_set.shape)\n",
    "\n",
    "train_path = 'pcl_train.tsv'\n",
    "test_path = 'pcl_test.tsv'\n",
    "\n",
    "with open(train_path, 'w') as f:\n",
    "    f.write('\\n'*4)\n",
    "    train_set.to_csv(f, header=False, sep ='\\t')\n",
    "\n",
    "with open(test_path, 'w') as f:\n",
    "    f.write('\\n'*4)\n",
    "    test_set.to_csv(f, header=False, sep ='\\t', index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "635a041e-71b0-456a-9b8f-94dfde73b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dont_patronize_me import DontPatronizeMe\n",
    "# Initialize a dpm (Don't Patronize Me) object.\n",
    "# It takes two arguments as input: \n",
    "# (1) Path to the directory containing the training set files, which is the root directory of this notebook.\n",
    "# (2) Path to the test set, which will be released when the evaluation phase begins. In this example, \n",
    "# we use the dataset for Subtask 1, which the code will load without labels.\n",
    "dpm = DontPatronizeMe('.', test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dd278d7-41c8-4f33-b808-e844435b1be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>par_id</th>\n",
       "      <th>art_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>orig_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@@24942188</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>ph</td>\n",
       "      <td>we 're living in times of absolute insanity , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@@21968160</td>\n",
       "      <td>migrant</td>\n",
       "      <td>gh</td>\n",
       "      <td>in libya today , there are countless number of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@@16584954</td>\n",
       "      <td>immigrant</td>\n",
       "      <td>ie</td>\n",
       "      <td>\"white house press secretary sean spicer said ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@@7811231</td>\n",
       "      <td>disabled</td>\n",
       "      <td>nz</td>\n",
       "      <td>council customers only signs would be displaye...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@@1494111</td>\n",
       "      <td>refugee</td>\n",
       "      <td>ca</td>\n",
       "      <td>\"\"\" just like we received migrants fleeing el ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>@@9382277</td>\n",
       "      <td>in-need</td>\n",
       "      <td>in</td>\n",
       "      <td>to bring down high blood sugar levels , insuli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>@@7562079</td>\n",
       "      <td>refugee</td>\n",
       "      <td>za</td>\n",
       "      <td>the european union is making an historic mista...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>@@23663488</td>\n",
       "      <td>hopeless</td>\n",
       "      <td>nz</td>\n",
       "      <td>\"\"\" they 're either hopeless for being beaten ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>@@3449225</td>\n",
       "      <td>homeless</td>\n",
       "      <td>ph</td>\n",
       "      <td>nueva era , ilocos norte - no family shall be ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>@@2485090</td>\n",
       "      <td>in-need</td>\n",
       "      <td>nz</td>\n",
       "      <td>his spokesman said the kremlin needed more inf...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  par_id      art_id    keyword country  \\\n",
       "0      1  @@24942188   hopeless      ph   \n",
       "1      2  @@21968160    migrant      gh   \n",
       "2      3  @@16584954  immigrant      ie   \n",
       "3      4   @@7811231   disabled      nz   \n",
       "4      5   @@1494111    refugee      ca   \n",
       "5      6   @@9382277    in-need      in   \n",
       "6      7   @@7562079    refugee      za   \n",
       "7      8  @@23663488   hopeless      nz   \n",
       "8      9   @@3449225   homeless      ph   \n",
       "9     10   @@2485090    in-need      nz   \n",
       "\n",
       "                                                text  label orig_label  \n",
       "0  we 're living in times of absolute insanity , ...      0          0  \n",
       "1  in libya today , there are countless number of...      0          0  \n",
       "2  \"white house press secretary sean spicer said ...      0          0  \n",
       "3  council customers only signs would be displaye...      0          0  \n",
       "4  \"\"\" just like we received migrants fleeing el ...      0          0  \n",
       "5  to bring down high blood sugar levels , insuli...      0          0  \n",
       "6  the european union is making an historic mista...      0          0  \n",
       "7  \"\"\" they 're either hopeless for being beaten ...      0          0  \n",
       "8  nueva era , ilocos norte - no family shall be ...      0          1  \n",
       "9  his spokesman said the kremlin needed more inf...      0          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This method loads the subtask 1 data\n",
    "dpm.load_task1()\n",
    "# which we can then access as a dataframe\n",
    "dpm.train_task1_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d592a6d-b88d-4ad8-8132-8c34557aa858",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set = dpm.train_task1_df.iloc[train_indices-1]\n",
    "test_set = dpm.train_task1_df.iloc[test_indices-1]\n",
    "\n",
    "# training set\n",
    "X_train = train_set.text.to_numpy()\n",
    "y_train = train_set.label.to_numpy()\n",
    "# print(X_train)\n",
    "# print(y_train)\n",
    "\n",
    "# test set\n",
    "X_test = test_set.text.to_numpy()\n",
    "y_test = test_set.label.to_numpy()\n",
    "# print(X_test)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85d5dda7-9bb3-4809-a305-d4453fcf58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to save predictions to an output file\n",
    "def labels2file(p, outf_path):\n",
    "\twith open(outf_path,'w') as outf:\n",
    "\t\tfor pi in p:\n",
    "\t\t\toutf.write(','.join([str(k) for k in pi])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "024d4679-bab6-4f72-9293-0320dcf4f5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: ref: File exists\n",
      "mkdir: res: File exists\n"
     ]
    }
   ],
   "source": [
    "# first, we need to create the res/ and ref/ folders, which the evaluator expects\n",
    "!mkdir ref res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e6abf72-cc73-4221-85ec-65bf40be7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpm.load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15fd06ca-9381-4fb5-b41b-c964734a9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dpm.test_set[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d0f69af-66d2-4276-ae25-73e8b6a41e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb1919b4-8c84-41fb-b222-8477ca8d2acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 15:07:06.391183: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-11 15:07:06.391210: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2021-12-11 15:07:06.411623: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-11 15:07:06.421615: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-12-11 15:07:06.433190: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 20), dtype=float32, numpy=\n",
       "array([[ 1.1180605 , -0.37061796, -0.12925693, -1.4085444 ,  1.6034535 ,\n",
       "        -2.2361784 ,  0.89861727,  0.6513086 , -0.19338463,  0.79440534,\n",
       "         0.972198  ,  0.2805785 , -2.545298  ,  0.04027791, -1.0220096 ,\n",
       "         1.5522635 ,  0.244063  , -2.2539005 ,  0.14072226,  0.7685297 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim-with-oov/1\"\n",
    "hub_layer = hub.KerasLayer(model, output_shape=[20], input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "hub_layer(X_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "919b752d-f327-4f99-9ddb-7c9d5f79fd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 20)                389380    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                1050      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 393,031\n",
      "Trainable params: 393,031\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >\n",
    "                0.998):  # it actually never reaches this hight accuracy\n",
    "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "\n",
    "# drops 1D feature maps for independence\n",
    "model.add(Dropout(0.1, input_shape=(20,)))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8de355b6-43ef-494c-a7c9-7f16214f4b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1102c9a-7aab-4733-b26b-5f0fd1bf5dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/262 [..............................] - ETA: 1:25 - loss: 1.4061 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 15:07:06.906466: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - ETA: 0s - loss: 0.3425 - accuracy: 0.8848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 15:07:10.918308: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 5s 16ms/step - loss: 0.3425 - accuracy: 0.8848 - val_loss: 0.2843 - val_accuracy: 0.9050\n",
      "Epoch 2/20\n",
      "262/262 [==============================] - 4s 15ms/step - loss: 0.2772 - accuracy: 0.9050 - val_loss: 0.2617 - val_accuracy: 0.9059\n",
      "Epoch 3/20\n",
      "262/262 [==============================] - 4s 15ms/step - loss: 0.2565 - accuracy: 0.9073 - val_loss: 0.2566 - val_accuracy: 0.9083\n",
      "Epoch 4/20\n",
      "262/262 [==============================] - 4s 15ms/step - loss: 0.2321 - accuracy: 0.9125 - val_loss: 0.2574 - val_accuracy: 0.9097\n",
      "Epoch 5/20\n",
      "262/262 [==============================] - 4s 15ms/step - loss: 0.2067 - accuracy: 0.9213 - val_loss: 0.2452 - val_accuracy: 0.9088\n",
      "Epoch 6/20\n",
      "262/262 [==============================] - 4s 15ms/step - loss: 0.1834 - accuracy: 0.9291 - val_loss: 0.2581 - val_accuracy: 0.9050\n",
      "Epoch 7/20\n",
      "262/262 [==============================] - 4s 15ms/step - loss: 0.1633 - accuracy: 0.9371 - val_loss: 0.2597 - val_accuracy: 0.9131\n",
      "Epoch 8/20\n",
      "262/262 [==============================] - 4s 15ms/step - loss: 0.1418 - accuracy: 0.9457 - val_loss: 0.2701 - val_accuracy: 0.9107\n",
      "Epoch 9/20\n",
      "262/262 [==============================] - 4s 15ms/step - loss: 0.1266 - accuracy: 0.9500 - val_loss: 0.2859 - val_accuracy: 0.9007\n",
      "Epoch 10/20\n",
      "262/262 [==============================] - 4s 15ms/step - loss: 0.1078 - accuracy: 0.9598 - val_loss: 0.3032 - val_accuracy: 0.9083\n",
      "Epoch 11/20\n",
      "262/262 [==============================] - 4s 15ms/step - loss: 0.0956 - accuracy: 0.9650 - val_loss: 0.3106 - val_accuracy: 0.8973\n",
      "Epoch 12/20\n",
      "262/262 [==============================] - 4s 16ms/step - loss: 0.0887 - accuracy: 0.9670 - val_loss: 0.3247 - val_accuracy: 0.8997\n",
      "Epoch 13/20\n",
      "262/262 [==============================] - 4s 16ms/step - loss: 0.0782 - accuracy: 0.9710 - val_loss: 0.3490 - val_accuracy: 0.9050\n",
      "Epoch 14/20\n",
      "262/262 [==============================] - 4s 16ms/step - loss: 0.0699 - accuracy: 0.9755 - val_loss: 0.3724 - val_accuracy: 0.8959\n",
      "Epoch 15/20\n",
      "262/262 [==============================] - 4s 15ms/step - loss: 0.0600 - accuracy: 0.9793 - val_loss: 0.4012 - val_accuracy: 0.8878\n",
      "Epoch 16/20\n",
      "262/262 [==============================] - 4s 15ms/step - loss: 0.0606 - accuracy: 0.9765 - val_loss: 0.4089 - val_accuracy: 0.9031\n",
      "Epoch 17/20\n",
      "262/262 [==============================] - 4s 16ms/step - loss: 0.0491 - accuracy: 0.9829 - val_loss: 0.4380 - val_accuracy: 0.9007\n",
      "Epoch 18/20\n",
      "262/262 [==============================] - 4s 15ms/step - loss: 0.0469 - accuracy: 0.9834 - val_loss: 0.4319 - val_accuracy: 0.9035\n",
      "Epoch 19/20\n",
      "262/262 [==============================] - 4s 16ms/step - loss: 0.0436 - accuracy: 0.9852 - val_loss: 0.4687 - val_accuracy: 0.8988\n",
      "Epoch 20/20\n",
      "262/262 [==============================] - 4s 15ms/step - loss: 0.0371 - accuracy: 0.9876 - val_loss: 0.4909 - val_accuracy: 0.9026\n",
      "CPU times: user 1min 4s, sys: 30.6 s, total: 1min 34s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=1,\n",
    "                    callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f5b70d6-f5e6-4169-9ea9-f22d1390aac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 5ms/step - loss: 0.4909 - accuracy: 0.9026\n",
      "Test loss: 0.49092382192611694\n",
      "Test accuracy: 0.9025787711143494\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose = 1) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20f261f0-b99a-406d-b7b5-deec06e250eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 15:08:27.763281: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 1951\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test) \n",
    "# print(pred)\n",
    "# pred = np.argmax(pred, axis = 1)[:5] \n",
    "# label = np.argmax(y_test,axis = 1)[:5] \n",
    "\n",
    "# print(pred) \n",
    "# print(label)\n",
    "pos = pred[pred >= 0.5]\n",
    "neg = pred[pred < 0.5]\n",
    "print(len(pos), len(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df6fc5aa-954a-43a5-80b7-e65b1e5e923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relabel\n",
    "pred[pred >= 0.5] = int(1)\n",
    "pred[pred < 0.5] = int(0)\n",
    "pred = pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af477273-2c04-4094-bced-4a4f7068449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to file\n",
    "labels2file(pred, os.path.join('res/', 'task1.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3450115f-2afb-4aad-aa15-fc7e97ed7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subtask 1 (we convert our list of labels into a list of lists to make \n",
    "# it compatible with the labels2file function)\n",
    "labels2file(test_set.label.apply(lambda x:[x]).tolist(), os.path.join('ref/', 'task1.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "119d02ca-807a-4687-bb9b-dd877d3ca8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can just call the official scorer, which takes an input_directory and an output_directory\n",
    "# as arguments. In this example, both will be the root directory of this notebook.\n",
    "!python3 evaluation.py . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b81cd15-34bb-4f90-8373-5bafb2461eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task1_precision:0.4825174825174825\n",
      "task1_recall:0.34673366834170855\n",
      "task1_f1:0.40350877192982454\n"
     ]
    }
   ],
   "source": [
    "# The scorer generated a results file called \"scores.txt\". \n",
    "# We can now see the performance of a random baseline on the training set.\n",
    "!cat scores.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a0688ea-150a-4be0-9965-f5373832ddae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: task1.txt (deflated 95%)\n"
     ]
    }
   ],
   "source": [
    "# the left pane should now show a file called submission.zip, which you can submit to Codalab\n",
    "!cp 'res/task1.txt' 'task1.txt'\n",
    "!zip submission.zip 'task1.txt'\n",
    "! rm 'task1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a36335b-fb33-4e8c-9a7d-c498d188f083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
